{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32adbd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
      "     ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/104.6 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 30.7/104.6 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------- ---- 92.2/104.6 kB 744.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 104.6/104.6 kB 857.9 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\avinash\\downloads\\my projects\\deep learning\\tf-env\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avinash\\downloads\\my projects\\deep learning\\tf-env\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\avinash\\downloads\\my projects\\deep learning\\tf-env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avinash\\downloads\\my projects\\deep learning\\tf-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/8.1 MB 6.4 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/8.1 MB 3.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.4/8.1 MB 3.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/8.1 MB 3.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/8.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/8.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.1/8.1 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/8.1 MB 3.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.3/8.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.6/8.1 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.5/8.1 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.8/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.0/8.1 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.3/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.6/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.6/8.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.3/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.7/8.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.4/8.1 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.1 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.9/8.1 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.7/8.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.1/8.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 5.5 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.4 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "   ---------------------------------------- 0.0/111.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 111.1/111.1 kB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f486757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40620d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6baf75c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e2f8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a235b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1cb250380>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65a0672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b348dd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5563f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e997c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.80925888e-07, 1.08555533e-06, 1.08555533e-06, 1.08555533e-06,\n",
       "        7.59888731e-06, 8.20197360e-06, 1.05540101e-05, 1.56802436e-06,\n",
       "        1.00112325e-05, 1.53787005e-05, 1.48962315e-05, 7.65919594e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.80925888e-06, 2.17111066e-06, 5.66901116e-06, 9.28752893e-06,\n",
       "        1.02524670e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.35694416e-05, 1.03730843e-05,\n",
       "        1.52580832e-05, 1.45946883e-05, 1.17601827e-05, 3.85975228e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.95512284e-06,\n",
       "        1.43534538e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.51374660e-05, 5.60870254e-06, 4.94530761e-06,\n",
       "        4.94530761e-06, 3.37728325e-06, 2.35203655e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.08555533e-06,\n",
       "        1.32075898e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.19411086e-05, 1.09761706e-05,\n",
       "        1.48962315e-05, 1.45343797e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.82469035e-06, 9.40814619e-06, 6.45302335e-06, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.23632690e-05, 6.63394924e-07, 0.00000000e+00,\n",
       "        2.59327106e-06, 9.28752893e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 8.44320812e-07, 6.03086294e-08, 9.28752893e-06,\n",
       "        1.52580832e-05, 5.42777665e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.38289949e-06,\n",
       "        1.52580832e-05, 1.14586396e-05, 1.20617259e-07, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63394924e-07,\n",
       "        1.14586396e-05, 1.52580832e-05, 4.22160406e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.11080203e-06, 1.45343797e-05, 1.35694416e-05, 9.64938071e-06,\n",
       "        6.51333198e-06, 6.03086294e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.88499898e-06, 1.44740711e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 7.17672690e-06, 1.50771574e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.71388832e-06, 1.12174051e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 9.04629441e-06, 1.62833299e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.64938071e-07,\n",
       "        5.60870254e-06, 1.51977746e-05, 1.52580832e-05, 1.12777137e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.50168487e-05, 1.52580832e-05, 1.50168487e-05,\n",
       "        3.85975228e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.77419695e-06, 7.84012182e-06,\n",
       "        1.10364792e-05, 1.52580832e-05, 1.52580832e-05, 1.24838863e-05,\n",
       "        1.20617259e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.35203655e-06, 8.92567715e-06, 1.38106761e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.50771574e-05, 1.09761706e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.44740711e-06, 6.87518375e-06,\n",
       "        1.33282071e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.21220345e-05, 4.70407309e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.38709848e-06, 3.98036954e-06, 1.28457381e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.52580832e-05, 1.19411086e-05,\n",
       "        4.88499898e-06, 1.20617259e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.08555533e-06, 1.03127756e-05,\n",
       "        1.32075898e-05, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.17601827e-05, 4.82469035e-06, 5.42777665e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.31697462e-06, 1.03730843e-05, 1.36297502e-05, 1.52580832e-05,\n",
       "        1.52580832e-05, 1.52580832e-05, 1.52580832e-05, 1.47153056e-05,\n",
       "        8.02104771e-06, 6.63394924e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.20197360e-06, 1.52580832e-05, 1.52580832e-05, 1.52580832e-05,\n",
       "        1.27854294e-05, 8.14166497e-06, 7.96073908e-06, 9.64938071e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f4902ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend = x_train.reshape(len(x_train), 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41f938e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63e57c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7ad3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2194243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48cf3542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b27fc622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 254, 254, 254,\n",
       "       254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 114,\n",
       "        72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254,\n",
       "       140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  17,  66,  14,  67,  67,  67,  59,  21,\n",
       "       236, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 133, 254, 187,   5,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   9, 205, 248,  58,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 254, 182,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  75, 251,\n",
       "       240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n",
       "       221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  31, 224, 254, 115,   1,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 133, 254, 254,  52,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  61, 242, 254, 254,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,  40,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "        18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cbf2089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.0967 - loss: 1.6075\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 0.2552\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 0.0648\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 0.0223\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 0.0085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e1d3116240>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape = (784,), activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(flattend, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58f20d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0924 - loss: 4781.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5008.3994140625, 0.09799999743700027]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(flat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51850f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (10000, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\pyplot.py:2673\u001b[39m, in \u001b[36mmatshow\u001b[39m\u001b[34m(A, fignum, **kwargs)\u001b[39m\n\u001b[32m   2671\u001b[39m     fig = figure(fignum, figsize=figsize)\n\u001b[32m   2672\u001b[39m     ax = fig.add_axes((\u001b[32m0.15\u001b[39m, \u001b[32m0.09\u001b[39m, \u001b[32m0.775\u001b[39m, \u001b[32m0.775\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m2673\u001b[39m im = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2674\u001b[39m sci(im)\n\u001b[32m   2675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:8470\u001b[39m, in \u001b[36mAxes.matshow\u001b[39m\u001b[34m(self, Z, **kwargs)\u001b[39m\n\u001b[32m   8465\u001b[39m Z = np.asanyarray(Z)\n\u001b[32m   8466\u001b[39m kw = {\u001b[33m'\u001b[39m\u001b[33morigin\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   8467\u001b[39m       \u001b[33m'\u001b[39m\u001b[33minterpolation\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   8468\u001b[39m       \u001b[33m'\u001b[39m\u001b[33maspect\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mequal\u001b[39m\u001b[33m'\u001b[39m,          \u001b[38;5;66;03m# (already the imshow default)\u001b[39;00m\n\u001b[32m   8469\u001b[39m       **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m8470\u001b[39m im = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8471\u001b[39m \u001b[38;5;28mself\u001b[39m.title.set_y(\u001b[32m1.05\u001b[39m)\n\u001b[32m   8472\u001b[39m \u001b[38;5;28mself\u001b[39m.xaxis.tick_top()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5976\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5974\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5976\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5977\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5979\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avinash\\Downloads\\my projects\\Deep learning\\tf-env\\Lib\\site-packages\\matplotlib\\image.py:653\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    651\u001b[39m     A = A.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A.shape[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for image data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[32m    659\u001b[39m     high = \u001b[32m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.issubdtype(A.dtype, np.integer) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Invalid shape (10000, 28, 28) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cf5cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac2012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
